# -*- coding: utf-8 -*-
"""MLProject1Exercises2a.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ItHicj5gdOBwY34N0Z3HnO2B7_XRLD3Z
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import StandardScaler
import tensorflow as tf

class PolinomialRegression:
    def __init__(self, x, y, degree, learning_rate=0.001):
        self.x = create_feature_matrix(x, degree)
        self.y = y
        # self.w = tf.Variable(tf.zeros(degree), dtype=tf.float32)
        self.w = tf.Variable(tf.random.uniform((degree,), 0, 1, dtype=tf.float32))
        self.b = tf.Variable(0.0, dtype=tf.float32)
        self.degree = degree
        self.learning_rate = learning_rate
        # Adam optimizator
        self.adam = tf.keras.optimizers.Adam(learning_rate=learning_rate)

    # Funkcija predikcije.
    def _pred(self, x, w, b):
        w_col = tf.reshape(w, (self.degree, 1))
        hyp = tf.add(tf.matmul(x, w_col), b)
        return hyp


    # Funkcija tro≈°ka i optimizacija.
    def _loss(self, x, y):
        prediction = self._pred(x, self.w, self.b)

        y_col = tf.reshape(y, (-1, 1))
        mse = tf.reduce_mean(tf.square(prediction - y_col))
        
        return mse



    # Racunanje gradijenta
    def _calc_grad(self, x, y):
        with tf.GradientTape() as tape:
            loss_val = self._loss(x, y)
        
        w_grad, b_grad = tape.gradient(loss_val, [self.w, self.b])

        return w_grad, b_grad, loss_val

    # Pojedinacno izracunavanje gradijenta.
    def _train_step(self, x, y):
        w_grad, b_grad, loss = self._calc_grad(x, y)

        self.adam.apply_gradients(zip([w_grad, b_grad], [self.w, self.b]))

        return loss

    # Trening.
    def fit(self, epochs=50):
        for epoch in range(epochs):
            
            # Stochastic Gradient Descent.
            for i in range(self.x.shape[0]):
                curr_x = self.x[i].reshape((1, self.degree))
                curr_y = self.y[i]

                self._train_step(curr_x, curr_y)

                

    def get_cost(self):
        avg_cost = 0
        for i in range(self.x.shape[0]):
            curr_x = self.x[i].reshape((1, self.degree))
            curr_y = self.y[i]
            loss_val = self._loss(curr_x, curr_y)
            avg_cost += loss_val

        return avg_cost / self.x.shape[0]
           
    def predict(self):
        predictions = []
        for i in range(self.x.shape[0]):
                curr_x = self.x[i].reshape((1, self.degree))
                predictions.append(self._pred(curr_x, self.w, self.b))
                # print(self._pred(curr_x, self.w, self.b))
        return predictions

# Pomocna funkcija za crtanje podataka.


# Pomocna funkcija koja od niza trening primera pravi feature matricu (m X n).
def create_feature_matrix(x, nb_features):
  tmp_features = []
  for deg in range(1, nb_features+1):
    tmp_features.append(np.power(x, deg))
  return np.column_stack(tmp_features)



# df = pd.read_csv('funky.csv', header=None)
filename = 'funky.csv'
all_data = np.loadtxt(filename, delimiter=',', skiprows=1, usecols=(0,1), dtype='float32')
scaler = StandardScaler()
raw_x = all_data[:, 0]
raw_y = all_data[:, 1]
# radimo normalizaciju zbog stepenovanja (6 stepen bi proizveo velike vrednosti)
xs = scaler.fit_transform(raw_x.reshape(-1, 1)).flatten().astype('float32')
ys = scaler.fit_transform(raw_y.reshape(-1, 1)).flatten().astype('float32')
# xs = raw_x
# ys = raw_y

all_costs = []
predictions = []  
max_degree = 6


# poly_reg = PolinomialRegression(xs, ys, 3)
# poly_reg.fit()
# print(poly_reg.get_cost())
# predictions.append(poly_reg.predict())
print(predictions)
for degree in range(1, max_degree+1):
    poly_reg = PolinomialRegression(xs, ys, degree)
    poly_reg.fit()
    all_costs.append(poly_reg.get_cost())
    predictions.append(poly_reg.predict())
print(predictions)

def plot_data(x, y, predictions,degree):
    colors=["red","blue","green","yellow","brown","purple"]
    plt.scatter(x.tolist(), y.tolist(), color='blue')
    plt.xlabel('x')
    plt.ylabel('y')
    for i in range(degree):
      c = i%6
      pred_arr = [elem.numpy().flatten()[0] for elem in predictions[i]]
      print(predictions[0])
      plt.scatter(x.tolist(), pred_arr, color=colors[c], marker='^')
    # pred_ar2 = [elem.numpy().flatten()[0] for elem in predictions[1]] 
    # plt.plot(x, pred_ar2, color='green')
    plt.show()


plot_data(xs, ys, predictions,6)

#Optimalno je koristiti pravu 3 stepena zato sto su podaci takvog oblika, ukoliko bismo koristili manji stepen onda bi bio underfitting a ako bismo veceg stepena, bespotrebno
#opterecujemo model a nemamo poboljsanja

def plot_costs(costs,degree):
  arr = [i for i in range(1,degree+1)]
  plt.plot(arr,costs)
  plt.xlabel('degree')
  plt.ylabel('costs')
  plt.show()

plot_costs(all_costs,6)