# -*- coding: utf-8 -*-
"""Project1Exercises3c.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iksNtxzJSdGH1HfB7GNtPmPA5Tt-oP0V
"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import pandas as pd

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

df = pd.read_csv('spaceship-titanic.csv')
lbl_enc = LabelEncoder()
df = df.dropna()

x = df.drop(['Transported'], axis=1)
y = df['Transported']


x['PassengerId'] = lbl_enc.fit_transform(x['PassengerId'])
x['HomePlanet'] = lbl_enc.fit_transform(x['HomePlanet'])
x['CryoSleep'] = lbl_enc.fit_transform(x['CryoSleep'])
x['Cabin'] = lbl_enc.fit_transform(x['Cabin'])
x['Destination'] = lbl_enc.fit_transform(x['Destination'])
x['VIP'] = lbl_enc.fit_transform(x['VIP'])
x['Name'] = lbl_enc.fit_transform(x['Name'])

scaler = StandardScaler()

x= scaler.fit_transform(x).astype('float32')


y = lbl_enc.fit_transform(y)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,  stratify=y)

class KNN:
  
    def __init__(self, nb_classes, x,y, k):
        self.nb_classes = nb_classes
        self.k = k
        self.X = x
        self.Y = y
  
    # Ako imamo odgovore za upit racunamo i accuracy.
    def accuracy(self, query_data):
        matches = 0
        for i in range(len(query_data['x'])):

            # Racunamo kvadriranu euklidsku udaljenost i uzimamo minimalnih k.
            dists = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(self.X, query_data['x'][i])), axis=1))
            _, idxs = tf.nn.top_k(-dists, self.k)
            classes = tf.gather(self.Y, idxs)
            dists = tf.gather(dists, idxs)
            
            w = tf.fill([self.k], 1/self.k)

            # Svaki red mnozimo svojim glasom i sabiramo glasove po kolonama.
            w_col = tf.reshape(w, (self.k, 1))
            classes_one_hot = tf.one_hot(classes, self.nb_classes)
            scores = tf.reduce_sum(w_col * classes_one_hot, axis=0)
            
            # Klasa sa najvise glasova je hipoteza.
            hyp = tf.argmax(scores)

            
            actual = query_data['y'][i]

            match = (hyp == actual)
            if match:
              matches += 1
                # if i % 100 == 0:
                #     a= len(query_data['y'])
                #     print(f'Test example: {i+1:2}/{a} | Predicted: {hyp} | Actual: {actual} | Match: {match}')
          
        acc = matches / len(query_data['x'])
        return acc


    def predict(self, query_data):
        y_pred = []
        matches = 0
        for i in range(len(query_data['x'])):

            # Racunamo kvadriranu euklidsku udaljenost i uzimamo minimalnih k.
            dists = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(self.X, query_data['x'][i])), axis=1))
            _, idxs = tf.nn.top_k(-dists, self.k)
            classes = tf.gather(self.Y, idxs)
            dists = tf.gather(dists, idxs)
            
            w = tf.fill([self.k], 1/self.k)

            # Svaki red mnozimo svojim glasom i sabiramo glasove po kolonama.
            w_col = tf.reshape(w, (self.k, 1))
            classes_one_hot = tf.one_hot(classes, self.nb_classes)
            scores = tf.reduce_sum(w_col * classes_one_hot, axis=0)
            
            # Klasa sa najvise glasova je hipoteza.
            hyp = tf.argmax(scores)

            y_pred.append(hyp)
          
        return y_pred

max_k = 50
acc_arr = []
for k in range(1, max_k+1):
  knn = KNN(2,x_train,y_train,k)
  acc = knn.accuracy({'x': x_test,'y': y_test})
  acc_arr.append(acc)

k_neighbours = np.arange(1, max_k+1)
plt.scatter(k_neighbours, acc_arr)

#kada su nam ukljuceni svi features onda je najbolji accuracy kada posmatramo 25 najblizih komsija, a kada imamo samo dva feature onda je najbolje posmatrati 20 najblizih komsija